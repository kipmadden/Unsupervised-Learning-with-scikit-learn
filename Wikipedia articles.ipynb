{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/wikipedia-vectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTTP 404</th>\n",
       "      <th>Alexa Internet</th>\n",
       "      <th>Internet Explorer</th>\n",
       "      <th>HTTP cookie</th>\n",
       "      <th>Google Search</th>\n",
       "      <th>Tumblr</th>\n",
       "      <th>Hypertext Transfer Protocol</th>\n",
       "      <th>Social search</th>\n",
       "      <th>Firefox</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>...</th>\n",
       "      <th>Chad Kroeger</th>\n",
       "      <th>Nate Ruess</th>\n",
       "      <th>The Wanted</th>\n",
       "      <th>Stevie Nicks</th>\n",
       "      <th>Arctic Monkeys</th>\n",
       "      <th>Black Sabbath</th>\n",
       "      <th>Skrillex</th>\n",
       "      <th>Red Hot Chili Peppers</th>\n",
       "      <th>Sepsis</th>\n",
       "      <th>Adam Levine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HTTP 404  Alexa Internet  Internet Explorer  HTTP cookie  Google Search  \\\n",
       "0       0.0        0.000000                0.0          0.0            0.0   \n",
       "1       0.0        0.000000                0.0          0.0            0.0   \n",
       "2       0.0        0.029607                0.0          0.0            0.0   \n",
       "3       0.0        0.000000                0.0          0.0            0.0   \n",
       "4       0.0        0.000000                0.0          0.0            0.0   \n",
       "\n",
       "   Tumblr  Hypertext Transfer Protocol  Social search  Firefox  LinkedIn  ...  \\\n",
       "0     0.0                          0.0            0.0      0.0       0.0  ...   \n",
       "1     0.0                          0.0            0.0      0.0       0.0  ...   \n",
       "2     0.0                          0.0            0.0      0.0       0.0  ...   \n",
       "3     0.0                          0.0            0.0      0.0       0.0  ...   \n",
       "4     0.0                          0.0            0.0      0.0       0.0  ...   \n",
       "\n",
       "   Chad Kroeger  Nate Ruess  The Wanted  Stevie Nicks  Arctic Monkeys  \\\n",
       "0           0.0         0.0         0.0      0.008878             0.0   \n",
       "1           0.0         0.0         0.0      0.000000             0.0   \n",
       "2           0.0         0.0         0.0      0.000000             0.0   \n",
       "3           0.0         0.0         0.0      0.000000             0.0   \n",
       "4           0.0         0.0         0.0      0.000000             0.0   \n",
       "\n",
       "   Black Sabbath  Skrillex  Red Hot Chili Peppers   Sepsis  Adam Levine  \n",
       "0            0.0  0.049502               0.000000  0.00000          0.0  \n",
       "1            0.0  0.000000               0.000000  0.00611          0.0  \n",
       "2            0.0  0.000000               0.000000  0.00000          0.0  \n",
       "3            0.0  0.000000               0.005646  0.00000          0.0  \n",
       "4            0.0  0.000000               0.000000  0.00000          0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13125, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = scipy.sparse.csr_matrix(documents).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 13125)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read vocabulary text file into an array named words\n",
    "with open('data/wikipedia-vocabulary-utf8.txt') as f:\n",
    "    words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13125"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Wikipedia articles using a pipeline with PCA and KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PCA model using TruncatedSVD in order to be able to use csr_matrix sparse matrixes\n",
    "svd = TruncatedSVD(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a KMeans instance\n",
    "kmeans = KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('truncatedsvd', TruncatedSVD(n_components=50)),\n",
       "                ('kmeans', KMeans(n_clusters=6))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the documents\n",
    "pipeline.fit(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label                                        article\n",
      "0       0                                       HTTP 404\n",
      "8       0                                        Firefox\n",
      "7       0                                  Social search\n",
      "6       0                    Hypertext Transfer Protocol\n",
      "5       0                                         Tumblr\n",
      "9       0                                       LinkedIn\n",
      "3       0                                    HTTP cookie\n",
      "2       0                              Internet Explorer\n",
      "1       0                                 Alexa Internet\n",
      "4       0                                  Google Search\n",
      "50      1                                   Chad Kroeger\n",
      "57      1                          Red Hot Chili Peppers\n",
      "56      1                                       Skrillex\n",
      "55      1                                  Black Sabbath\n",
      "54      1                                 Arctic Monkeys\n",
      "53      1                                   Stevie Nicks\n",
      "52      1                                     The Wanted\n",
      "51      1                                     Nate Ruess\n",
      "58      1                                         Sepsis\n",
      "59      1                                    Adam Levine\n",
      "10      2                                 Global warming\n",
      "11      2       Nationally Appropriate Mitigation Action\n",
      "12      2                                   Nigel Lawson\n",
      "13      2                               Connie Hedegaard\n",
      "14      2                                 Climate change\n",
      "15      2                                 Kyoto Protocol\n",
      "16      2                                        350.org\n",
      "17      2  Greenhouse gas emissions by the United States\n",
      "18      2  2010 United Nations Climate Change Conference\n",
      "47      2                                          Fever\n",
      "19      2  2007 United Nations Climate Change Conference\n",
      "39      3                                  Franck Ribéry\n",
      "38      3                                         Neymar\n",
      "37      3                                       Football\n",
      "36      3              2014 FIFA World Cup qualification\n",
      "34      3                             Zlatan Ibrahimović\n",
      "33      3                                 Radamel Falcao\n",
      "32      3                                   Arsenal F.C.\n",
      "31      3                              Cristiano Ronaldo\n",
      "30      3                  France national football team\n",
      "35      3                Colombia national football team\n",
      "48      4                                     Gabapentin\n",
      "40      4                                    Tonsillitis\n",
      "41      4                                    Hepatitis B\n",
      "42      4                                    Doxycycline\n",
      "43      4                                       Leukemia\n",
      "44      4                                           Gout\n",
      "45      4                                    Hepatitis C\n",
      "46      4                                     Prednisone\n",
      "49      4                                       Lymphoma\n",
      "20      5                                 Angelina Jolie\n",
      "27      5                                 Dakota Fanning\n",
      "26      5                                     Mila Kunis\n",
      "25      5                                  Russell Crowe\n",
      "24      5                                   Jessica Biel\n",
      "23      5                           Catherine Zeta-Jones\n",
      "22      5                              Denzel Washington\n",
      "21      5                             Michael Fassbender\n",
      "28      5                                  Anne Hathaway\n",
      "29      5                               Jennifer Aniston\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame aligning labels and titles: df\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df.sort_values('label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF applied to Wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an NMF model\n",
    "model = NMF(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:315: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  \"'nndsvda' in 1.1 (renaming of 0.26).\"), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the articles csr_matrix\n",
    "model.fit(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 13125)\n"
     ]
    }
   ],
   "source": [
    "print(articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 13125)\n"
     ]
    }
   ],
   "source": [
    "print(model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.44]\n",
      " [0.   0.   0.   0.   0.   0.57]\n",
      " [0.   0.   0.   0.   0.   0.4 ]\n",
      " [0.   0.   0.   0.   0.   0.38]\n",
      " [0.   0.   0.   0.   0.   0.49]\n",
      " [0.01 0.01 0.01 0.03 0.   0.33]\n",
      " [0.   0.   0.02 0.   0.01 0.36]\n",
      " [0.   0.   0.   0.   0.   0.49]\n",
      " [0.02 0.01 0.   0.02 0.03 0.48]\n",
      " [0.01 0.03 0.03 0.07 0.02 0.34]\n",
      " [0.   0.   0.53 0.   0.03 0.  ]\n",
      " [0.   0.   0.36 0.   0.   0.  ]\n",
      " [0.01 0.01 0.31 0.06 0.01 0.02]\n",
      " [0.   0.01 0.34 0.01 0.   0.  ]\n",
      " [0.   0.   0.43 0.   0.04 0.  ]\n",
      " [0.   0.   0.48 0.   0.   0.  ]\n",
      " [0.01 0.02 0.38 0.03 0.   0.01]\n",
      " [0.   0.   0.48 0.   0.   0.  ]\n",
      " [0.   0.01 0.55 0.   0.   0.  ]\n",
      " [0.   0.   0.47 0.   0.   0.  ]\n",
      " [0.   0.01 0.02 0.52 0.06 0.01]\n",
      " [0.   0.   0.   0.51 0.   0.  ]\n",
      " [0.   0.01 0.   0.42 0.   0.  ]\n",
      " [0.   0.   0.   0.44 0.   0.  ]\n",
      " [0.   0.   0.   0.5  0.   0.  ]\n",
      " [0.1  0.09 0.   0.38 0.   0.01]\n",
      " [0.   0.   0.   0.57 0.   0.01]\n",
      " [0.01 0.01 0.   0.47 0.   0.01]\n",
      " [0.   0.   0.   0.58 0.   0.  ]\n",
      " [0.   0.   0.   0.53 0.01 0.01]\n",
      " [0.   0.41 0.   0.   0.   0.  ]\n",
      " [0.   0.61 0.   0.01 0.   0.  ]\n",
      " [0.01 0.27 0.   0.02 0.01 0.  ]\n",
      " [0.   0.64 0.   0.   0.   0.  ]\n",
      " [0.   0.61 0.   0.   0.   0.  ]\n",
      " [0.   0.34 0.   0.   0.   0.  ]\n",
      " [0.01 0.32 0.02 0.   0.01 0.  ]\n",
      " [0.01 0.21 0.01 0.05 0.02 0.01]\n",
      " [0.01 0.47 0.   0.02 0.   0.  ]\n",
      " [0.   0.64 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.48 0.  ]\n",
      " [0.   0.   0.   0.   0.49 0.  ]\n",
      " [0.   0.   0.   0.   0.38 0.01]\n",
      " [0.   0.   0.   0.01 0.54 0.  ]\n",
      " [0.   0.   0.01 0.   0.42 0.  ]\n",
      " [0.   0.   0.   0.   0.51 0.  ]\n",
      " [0.   0.   0.   0.   0.37 0.  ]\n",
      " [0.   0.   0.04 0.   0.23 0.  ]\n",
      " [0.01 0.   0.02 0.01 0.33 0.04]\n",
      " [0.   0.   0.   0.   0.42 0.  ]\n",
      " [0.31 0.   0.   0.   0.   0.  ]\n",
      " [0.37 0.   0.   0.   0.   0.  ]\n",
      " [0.4  0.03 0.   0.02 0.   0.02]\n",
      " [0.38 0.   0.   0.04 0.   0.01]\n",
      " [0.44 0.   0.   0.   0.   0.  ]\n",
      " [0.46 0.   0.   0.   0.   0.  ]\n",
      " [0.28 0.   0.   0.05 0.   0.02]\n",
      " [0.45 0.   0.   0.   0.01 0.  ]\n",
      " [0.29 0.01 0.01 0.01 0.19 0.01]\n",
      " [0.38 0.01 0.   0.1  0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the NMF features\n",
    "print(nmf_features.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame to view the nmf_features\n",
    "df = pd.DataFrame(nmf_features, index=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HTTP 404', 'Alexa Internet', 'Internet Explorer', 'HTTP cookie',\n",
       "       'Google Search', 'Tumblr', 'Hypertext Transfer Protocol',\n",
       "       'Social search', 'Firefox', 'LinkedIn', 'Global warming',\n",
       "       'Nationally Appropriate Mitigation Action', 'Nigel Lawson',\n",
       "       'Connie Hedegaard', 'Climate change', 'Kyoto Protocol', '350.org',\n",
       "       'Greenhouse gas emissions by the United States',\n",
       "       '2010 United Nations Climate Change Conference',\n",
       "       '2007 United Nations Climate Change Conference', 'Angelina Jolie',\n",
       "       'Michael Fassbender', 'Denzel Washington', 'Catherine Zeta-Jones',\n",
       "       'Jessica Biel', 'Russell Crowe', 'Mila Kunis', 'Dakota Fanning',\n",
       "       'Anne Hathaway', 'Jennifer Aniston', 'France national football team',\n",
       "       'Cristiano Ronaldo', 'Arsenal F.C.', 'Radamel Falcao',\n",
       "       'Zlatan Ibrahimović', 'Colombia national football team',\n",
       "       '2014 FIFA World Cup qualification', 'Football', 'Neymar',\n",
       "       'Franck Ribéry', 'Tonsillitis', 'Hepatitis B', 'Doxycycline',\n",
       "       'Leukemia', 'Gout', 'Hepatitis C', 'Prednisone', 'Fever', 'Gabapentin',\n",
       "       'Lymphoma', 'Chad Kroeger', 'Nate Ruess', 'The Wanted', 'Stevie Nicks',\n",
       "       'Arctic Monkeys', 'Black Sabbath', 'Skrillex', 'Red Hot Chili Peppers',\n",
       "       'Sepsis', 'Adam Levine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.003846\n",
       "1    0.000000\n",
       "2    0.000000\n",
       "3    0.575626\n",
       "4    0.000000\n",
       "5    0.000000\n",
       "Name: Anne Hathaway, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Anne Hathaway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.005601\n",
       "2    0.000000\n",
       "3    0.422318\n",
       "4    0.000000\n",
       "5    0.000000\n",
       "Name: Denzel Washington, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Denzel Washington']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these articles are reconstructed using primarily the 4th NMF component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from components of the model\n",
    "components_df = pd.DataFrame(model.components_, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 13125)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the DataFrame\n",
    "components_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 4th row\n",
    "component = components_df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film       0.627969\n",
      "award      0.253169\n",
      "starred    0.245320\n",
      "role       0.211482\n",
      "actress    0.186425\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the 5 largest words to establish the \"theme\"\n",
    "print(component.nlargest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic of the 4th NMF component looks related to film awards and who starred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similar artilce to 'Christiano Ronaldo' using cosine similarity of nmf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependency 'normalize' to normalize the nmf_features array\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the NMF features : norm_features\n",
    "norm_features = normalize(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the row corresponding to 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dot products to get the cosine similarities\n",
    "similarities = df.dot(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cristiano Ronaldo                  1.000000\n",
       "Franck Ribéry                      0.999972\n",
       "Radamel Falcao                     0.999942\n",
       "Zlatan Ibrahimović                 0.999942\n",
       "France national football team      0.999923\n",
       "Colombia national football team    0.999897\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the top 5 results with the largets cosine similarities\n",
    "similarities.nlargest(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
